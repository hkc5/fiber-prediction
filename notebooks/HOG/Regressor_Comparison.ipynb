{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Different Regressors for Fiber Orientation\n",
    "\n",
    "This notebook evaluates various regression models with 5-fold cross-validation:\n",
    "1. Support Vector Regression (SVR)\n",
    "2. Random Forest\n",
    "3. XGBoost\n",
    "4. Linear Models (Ridge, Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Regressors\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "import xgboost as xgb\n",
    "\n",
    "# Add src directory to Python path\n",
    "sys.path.append(os.path.abspath('../../src'))\n",
    "from fiber_predictor.svr_hog.feature_extraction import HogFeatureExtractor\n",
    "from fiber_predictor.svr_hog.data_processing import HogDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 4711\n",
      "Original features: 440\n",
      "PCA features: 138\n"
     ]
    }
   ],
   "source": [
    "# Data preparation\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Load data\n",
    "dataset = HogDataset(\n",
    "    labels_path=\"../images/bio/labels.csv\",\n",
    "    file_dir=\"../images/bio/\",\n",
    "    grid_quotient=np.arange(1, 6),\n",
    "    orientations=8,\n",
    "    augment_whole_dataset=True\n",
    ")\n",
    "\n",
    "# Extract features\n",
    "X = []\n",
    "y = []\n",
    "for idx in range(len(dataset)):\n",
    "    _, features, angle = dataset[idx]\n",
    "    X.append(features.numpy())\n",
    "    y.append(angle)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Preprocess\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "pca = PCA(n_components=0.95)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(f\"Total samples: {len(y)}\")\n",
    "print(f\"Original features: {X.shape[1]}\")\n",
    "print(f\"PCA features: {X_pca.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate and track model results\n",
    "def evaluate_model(model_name, model, param_distributions, n_iter=20):\n",
    "    random_search = RandomizedSearchCV(\n",
    "        model, param_distributions, \n",
    "        n_iter=n_iter,\n",
    "        cv=cv,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        n_jobs=-1, \n",
    "        verbose=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    random_search.fit(X_pca, y)\n",
    "    \n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Best parameters: {random_search.best_params_}\")\n",
    "    print(f\"Best MAE: {-random_search.best_score_:.2f}째\")\n",
    "    \n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'params': random_search.best_params_,\n",
    "        'mae': -random_search.best_score_,\n",
    "        'std': random_search.cv_results_['std_test_score'][random_search.best_index_]\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] END C=278.2559402207126, epsilon=0.01, gamma=0.0001, kernel=poly; total time=   2.8s\n",
      "[CV] END C=278.2559402207126, epsilon=0.01, gamma=0.0001, kernel=poly; total time=   2.8s\n",
      "[CV] END C=278.2559402207126, epsilon=0.01, gamma=0.0001, kernel=poly; total time=   2.8s\n",
      "[CV] END C=21.544346900318846, epsilon=0.01, gamma=0.0001, kernel=poly; total time=   2.8s\n",
      "[CV] END C=278.2559402207126, epsilon=0.01, gamma=0.0001, kernel=poly; total time=   2.9s\n",
      "[CV] END C=21.544346900318846, epsilon=0.01, gamma=0.0001, kernel=poly; total time=   2.9s\n",
      "[CV] END C=278.2559402207126, epsilon=0.01, gamma=0.0001, kernel=poly; total time=   2.9s\n",
      "[CV] END C=21.544346900318846, epsilon=0.01, gamma=0.0001, kernel=poly; total time=   2.8s\n",
      "[CV] END C=21.544346900318846, epsilon=0.01, gamma=0.0001, kernel=poly; total time=   2.9s\n",
      "[CV] END C=21.544346900318846, epsilon=0.01, gamma=0.0001, kernel=poly; total time=   3.0s\n",
      "[CV] END C=0.03593813663804628, epsilon=0.1, gamma=auto, kernel=rbf; total time=   3.7s\n",
      "[CV] END C=0.464158883361278, epsilon=0.01, gamma=0.01, kernel=poly; total time=   4.0s\n",
      "[CV] END C=0.464158883361278, epsilon=0.01, gamma=0.01, kernel=poly; total time=   4.0s\n",
      "[CV] END C=0.464158883361278, epsilon=0.01, gamma=0.01, kernel=poly; total time=   4.1s\n",
      "[CV] END C=0.464158883361278, epsilon=0.01, gamma=0.01, kernel=poly; total time=   4.1s\n",
      "[CV] END C=0.464158883361278, epsilon=0.01, gamma=0.01, kernel=poly; total time=   4.1s\n",
      "[CV] END C=0.03593813663804628, epsilon=0.1, gamma=auto, kernel=rbf; total time=   3.7s\n",
      "[CV] END C=0.03593813663804628, epsilon=0.1, gamma=auto, kernel=rbf; total time=   3.8s\n",
      "[CV] END C=0.03593813663804628, epsilon=0.1, gamma=auto, kernel=rbf; total time=   3.8s\n",
      "[CV] END C=0.03593813663804628, epsilon=0.1, gamma=auto, kernel=rbf; total time=   3.9s\n",
      "[CV] END C=5.994842503189409, epsilon=0.2, gamma=0.1, kernel=rbf; total time=   3.9s\n",
      "[CV] END C=5.994842503189409, epsilon=0.2, gamma=0.1, kernel=rbf; total time=   3.8s\n",
      "[CV] END C=5.994842503189409, epsilon=0.2, gamma=0.1, kernel=rbf; total time=   3.8s\n",
      "[CV] END C=5.994842503189409, epsilon=0.2, gamma=0.1, kernel=rbf; total time=   3.9s\n",
      "[CV] END C=5.994842503189409, epsilon=0.2, gamma=0.1, kernel=rbf; total time=   3.7s\n",
      "[CV] END C=0.1291549665014884, epsilon=0.1, gamma=scale, kernel=rbf; total time=   3.7s\n",
      "[CV] END C=0.1291549665014884, epsilon=0.1, gamma=scale, kernel=rbf; total time=   3.6s\n",
      "[CV] END C=0.1291549665014884, epsilon=0.1, gamma=scale, kernel=rbf; total time=   3.6s\n",
      "[CV] END C=0.1291549665014884, epsilon=0.1, gamma=scale, kernel=rbf; total time=   3.7s\n",
      "[CV] END C=0.1291549665014884, epsilon=0.1, gamma=scale, kernel=rbf; total time=   3.7s\n",
      "[CV] END C=1.6681005372000592, epsilon=0.2, gamma=0.001, kernel=rbf; total time=   3.8s\n",
      "[CV] END C=1.6681005372000592, epsilon=0.2, gamma=0.001, kernel=rbf; total time=   3.7s\n",
      "[CV] END C=1.6681005372000592, epsilon=0.2, gamma=0.001, kernel=rbf; total time=   3.8s\n",
      "[CV] END C=1.6681005372000592, epsilon=0.2, gamma=0.001, kernel=rbf; total time=   3.9s\n",
      "[CV] END C=1.6681005372000592, epsilon=0.2, gamma=0.001, kernel=rbf; total time=   4.0s\n",
      "[CV] END C=5.994842503189409, epsilon=0.05, gamma=auto, kernel=rbf; total time=   4.0s\n",
      "[CV] END C=5.994842503189409, epsilon=0.05, gamma=auto, kernel=rbf; total time=   4.0s\n",
      "[CV] END C=5.994842503189409, epsilon=0.05, gamma=auto, kernel=rbf; total time=   4.0s\n",
      "[CV] END C=5.994842503189409, epsilon=0.05, gamma=auto, kernel=rbf; total time=   3.9s\n",
      "[CV] END C=5.994842503189409, epsilon=0.05, gamma=auto, kernel=rbf; total time=   4.0s\n",
      "[CV] END C=0.03593813663804628, epsilon=0.2, gamma=auto, kernel=poly; total time=   3.0s\n",
      "[CV] END C=0.03593813663804628, epsilon=0.2, gamma=auto, kernel=poly; total time=   3.0s\n",
      "[CV] END C=0.03593813663804628, epsilon=0.2, gamma=auto, kernel=poly; total time=   2.9s\n",
      "[CV] END C=0.03593813663804628, epsilon=0.2, gamma=auto, kernel=poly; total time=   2.9s\n",
      "[CV] END C=0.03593813663804628, epsilon=0.2, gamma=auto, kernel=poly; total time=   3.0s\n",
      "[CV] END C=77.42636826811278, epsilon=0.05, gamma=0.0001, kernel=rbf; total time=   3.6s\n",
      "[CV] END C=77.42636826811278, epsilon=0.05, gamma=0.0001, kernel=rbf; total time=   3.7s\n",
      "[CV] END C=77.42636826811278, epsilon=0.05, gamma=0.0001, kernel=rbf; total time=   3.6s\n",
      "[CV] END ....C=1000.0, epsilon=0.05, gamma=scale, kernel=rbf; total time=   8.6s\n",
      "[CV] END ....C=1000.0, epsilon=0.05, gamma=scale, kernel=rbf; total time=   8.6s\n",
      "[CV] END ....C=1000.0, epsilon=0.05, gamma=scale, kernel=rbf; total time=   8.8s\n",
      "[CV] END ....C=1000.0, epsilon=0.05, gamma=scale, kernel=rbf; total time=   8.7s\n",
      "[CV] END C=77.42636826811278, epsilon=0.05, gamma=0.0001, kernel=rbf; total time=   3.9s\n",
      "[CV] END ....C=1000.0, epsilon=0.05, gamma=scale, kernel=rbf; total time=   8.8s\n",
      "[CV] END C=77.42636826811278, epsilon=0.05, gamma=0.0001, kernel=rbf; total time=   4.0s\n",
      "[CV] END ....C=1000.0, epsilon=0.2, gamma=0.001, kernel=poly; total time=   5.2s\n",
      "[CV] END C=0.1291549665014884, epsilon=0.2, gamma=scale, kernel=poly; total time=   3.3s\n",
      "[CV] END C=0.1291549665014884, epsilon=0.2, gamma=scale, kernel=poly; total time=   3.4s\n",
      "[CV] END C=0.1291549665014884, epsilon=0.2, gamma=scale, kernel=poly; total time=   3.3s\n",
      "[CV] END ....C=1000.0, epsilon=0.2, gamma=0.001, kernel=poly; total time=   6.2s\n",
      "[CV] END ....C=1000.0, epsilon=0.2, gamma=0.001, kernel=poly; total time=   6.0s\n",
      "[CV] END ....C=1000.0, epsilon=0.2, gamma=0.001, kernel=poly; total time=   6.3s\n",
      "[CV] END C=0.1291549665014884, epsilon=0.2, gamma=scale, kernel=poly; total time=   3.9s\n",
      "[CV] END ....C=1000.0, epsilon=0.2, gamma=0.001, kernel=poly; total time=   6.6s\n",
      "[CV] END C=0.1291549665014884, epsilon=0.2, gamma=scale, kernel=poly; total time=   3.8s\n",
      "[CV] END C=1.6681005372000592, epsilon=0.2, gamma=0.01, kernel=poly; total time=   6.1s\n",
      "[CV] END C=1.6681005372000592, epsilon=0.2, gamma=0.01, kernel=poly; total time=   5.6s\n",
      "[CV] END C=1.6681005372000592, epsilon=0.2, gamma=0.01, kernel=poly; total time=   5.5s\n",
      "[CV] END ........C=0.01, epsilon=0.2, gamma=1.0, kernel=poly; total time=  12.5s\n",
      "[CV] END C=0.464158883361278, epsilon=0.01, gamma=0.0001, kernel=rbf; total time=   3.6s\n",
      "[CV] END ........C=0.01, epsilon=0.2, gamma=1.0, kernel=poly; total time=  12.0s\n",
      "[CV] END ........C=0.01, epsilon=0.2, gamma=1.0, kernel=poly; total time=  11.9s\n",
      "[CV] END ........C=0.01, epsilon=0.2, gamma=1.0, kernel=poly; total time=  12.1s\n",
      "[CV] END ........C=0.01, epsilon=0.2, gamma=1.0, kernel=poly; total time=  13.2s\n",
      "[CV] END C=1.6681005372000592, epsilon=0.2, gamma=0.01, kernel=poly; total time=   5.5s\n",
      "[CV] END C=1.6681005372000592, epsilon=0.2, gamma=0.01, kernel=poly; total time=   5.7s\n",
      "[CV] END C=0.464158883361278, epsilon=0.01, gamma=0.0001, kernel=rbf; total time=   4.1s\n",
      "[CV] END C=0.464158883361278, epsilon=0.01, gamma=0.0001, kernel=rbf; total time=   4.2s\n",
      "[CV] END C=0.464158883361278, epsilon=0.01, gamma=0.0001, kernel=rbf; total time=   4.5s\n",
      "[CV] END C=0.464158883361278, epsilon=0.01, gamma=0.0001, kernel=rbf; total time=   4.5s\n",
      "[CV] END C=0.1291549665014884, epsilon=0.2, gamma=0.1, kernel=poly; total time=   9.2s\n",
      "[CV] END .....C=1000.0, epsilon=0.01, gamma=1.0, kernel=poly; total time=  13.3s\n",
      "[CV] END C=0.1291549665014884, epsilon=0.2, gamma=0.1, kernel=poly; total time=   8.9s\n",
      "[CV] END .....C=1000.0, epsilon=0.01, gamma=1.0, kernel=poly; total time=  13.4s\n",
      "[CV] END .....C=1000.0, epsilon=0.01, gamma=1.0, kernel=poly; total time=  13.3s\n",
      "[CV] END C=0.1291549665014884, epsilon=0.2, gamma=0.1, kernel=poly; total time=   9.2s\n",
      "[CV] END .....C=1000.0, epsilon=0.01, gamma=1.0, kernel=poly; total time=  12.5s\n",
      "[CV] END C=0.1291549665014884, epsilon=0.1, gamma=0.0001, kernel=rbf; total time=   3.5s\n",
      "[CV] END C=0.1291549665014884, epsilon=0.1, gamma=0.0001, kernel=rbf; total time=   3.5s\n",
      "[CV] END C=0.1291549665014884, epsilon=0.1, gamma=0.0001, kernel=rbf; total time=   3.6s\n",
      "[CV] END C=0.1291549665014884, epsilon=0.1, gamma=0.0001, kernel=rbf; total time=   3.7s\n",
      "[CV] END .....C=1000.0, epsilon=0.01, gamma=1.0, kernel=poly; total time=  18.3s\n",
      "[CV] END C=0.1291549665014884, epsilon=0.1, gamma=0.0001, kernel=rbf; total time=   4.0s\n",
      "[CV] END C=0.464158883361278, epsilon=0.1, gamma=0.01, kernel=rbf; total time=   4.5s\n",
      "[CV] END C=0.464158883361278, epsilon=0.1, gamma=0.01, kernel=rbf; total time=   4.7s\n",
      "[CV] END C=0.464158883361278, epsilon=0.1, gamma=0.01, kernel=rbf; total time=   4.5s\n",
      "[CV] END C=0.464158883361278, epsilon=0.1, gamma=0.01, kernel=rbf; total time=   4.4s\n",
      "[CV] END C=0.1291549665014884, epsilon=0.2, gamma=0.1, kernel=poly; total time=   9.7s\n",
      "[CV] END C=0.464158883361278, epsilon=0.1, gamma=0.01, kernel=rbf; total time=   3.3s\n",
      "[CV] END C=0.1291549665014884, epsilon=0.2, gamma=0.1, kernel=poly; total time=   9.4s\n",
      "\n",
      "SVR Results:\n",
      "Best parameters: {'kernel': 'rbf', 'gamma': 'scale', 'epsilon': 0.05, 'C': np.float64(1000.0)}\n",
      "Best MAE: 13.19째\n",
      "SVR training time: 74.39 seconds\n"
     ]
    }
   ],
   "source": [
    "# SVR evaluation\n",
    "start_time = time.time()\n",
    "svr_params = {\n",
    "    'kernel': ['rbf', 'poly'],\n",
    "    'C': np.logspace(-2, 3, 10),\n",
    "    'gamma': ['scale', 'auto'] + list(np.logspace(-4, 0, 5)),\n",
    "    'epsilon': [0.01, 0.05, 0.1, 0.2]\n",
    "}\n",
    "svr_results = evaluate_model('SVR', SVR(), svr_params)\n",
    "svr_results['time'] = time.time() - start_time\n",
    "print(f\"SVR training time: {svr_results['time']:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   2.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   2.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   2.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.9s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   4.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   4.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   4.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   4.6s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   4.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   4.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   4.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   4.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   4.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   4.8s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   7.8s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   7.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   7.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   4.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   3.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   3.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   7.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   3.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   3.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   7.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   8.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   8.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   8.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   8.4s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   5.8s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   5.7s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   5.7s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   8.2s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   5.8s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   5.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.8s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   3.5s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  16.1s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  16.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   3.3s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  16.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   3.4s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  16.2s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  16.6s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   3.5s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   3.5s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   5.1s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   5.1s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   5.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   8.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   8.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   8.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   8.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   8.7s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   5.1s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   5.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   3.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   3.4s\n",
      "[CV] END max_depth=15, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   6.8s\n",
      "[CV] END max_depth=15, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   6.8s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   3.4s\n",
      "[CV] END max_depth=15, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   6.8s\n",
      "[CV] END max_depth=15, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   6.9s\n",
      "[CV] END max_depth=15, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   6.8s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   3.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/fiber-orientation/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "25 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "23 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/fiber-orientation/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/fiber-orientation/lib/python3.12/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/fiber-orientation/lib/python3.12/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/fiber-orientation/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/fiber-orientation/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/fiber-orientation/lib/python3.12/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/fiber-orientation/lib/python3.12/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/fiber-orientation/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/fiber-orientation/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [-29.06016634 -24.49245887 -28.91038646          nan -24.95536994\n",
      " -24.77074985 -22.40945067 -19.19309214 -19.09620518          nan\n",
      " -32.66925727 -29.07583717          nan -24.96440158 -28.98307695\n",
      "          nan          nan -37.66169846 -24.79371049 -24.71448496]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Results:\n",
      "Best parameters: {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 15}\n",
      "Best MAE: 19.10째\n",
      "Random Forest training time: 64.14 seconds\n"
     ]
    }
   ],
   "source": [
    "# Random Forest evaluation\n",
    "start_time = time.time()\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100, 150, 200, 300],\n",
    "    'max_depth': [5, 10, 15, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "rf_results = evaluate_model('Random Forest', RandomForestRegressor(random_state=42), rf_params)\n",
    "rf_results['time'] = time.time() - start_time\n",
    "print(f\"Random Forest training time: {rf_results['time']:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.9; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.9; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.9; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.9; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.9; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.01, max_depth=6, n_estimators=50, subsample=0.6; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.01, max_depth=6, n_estimators=50, subsample=0.6; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.01, max_depth=6, n_estimators=50, subsample=0.6; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.01, max_depth=6, n_estimators=50, subsample=0.6; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.01, max_depth=6, n_estimators=50, subsample=0.6; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.6; total time=   9.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.6; total time=   9.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.6; total time=   9.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.6; total time=   9.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.6; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.7; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.7; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.7; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.7; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.7; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.6; total time=  12.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.6; total time=  14.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.6; total time=  14.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.7; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.6; total time=  13.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.6; total time=  13.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/fiber-orientation/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.7; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.7; total time=  11.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=0.8; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.7; total time=  14.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.7; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=0.8; total time=   8.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=0.8; total time=   9.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=0.8; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=0.8; total time=   8.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=  12.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=  14.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.6; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=  12.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.6; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.6; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.6; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.6; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.7; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.7; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.7; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.7; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.7; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.7; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.7; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.7; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.7; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.7; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=50, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, n_estimators=300, subsample=0.9; total time=  11.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=50, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=50, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, n_estimators=300, subsample=0.9; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, n_estimators=300, subsample=0.9; total time=  12.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, n_estimators=300, subsample=0.9; total time=  11.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, n_estimators=300, subsample=0.9; total time=  14.4s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.7; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.7; total time=   7.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.7; total time=   7.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.7; total time=   7.3s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.7; total time=   8.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   4.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   4.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=0.6; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=0.6; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=0.6; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=0.6; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=0.6; total time=   1.9s\n",
      "\n",
      "XGBoost Results:\n",
      "Best parameters: {'subsample': 0.9, 'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.2, 'gamma': 0.1, 'colsample_bytree': 0.9}\n",
      "Best MAE: 10.34째\n",
      "XGBoost training time: 78.51 seconds\n"
     ]
    }
   ],
   "source": [
    "# XGBoost evaluation\n",
    "start_time = time.time()\n",
    "xgb_params = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3]\n",
    "}\n",
    "xgb_results = evaluate_model('XGBoost', xgb.XGBRegressor(random_state=42), xgb_params)\n",
    "xgb_results['time'] = time.time() - start_time\n",
    "print(f\"XGBoost training time: {xgb_results['time']:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] END alpha=0.615848211066026, max_iter=2000, selection=cyclic, tol=0.01; total time=   0.0s[CV] END alpha=0.615848211066026, max_iter=2000, selection=cyclic, tol=0.01; total time=   0.0s\n",
      "\n",
      "[CV] END alpha=0.615848211066026, max_iter=2000, selection=cyclic, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.615848211066026, max_iter=2000, selection=cyclic, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.615848211066026, max_iter=2000, selection=cyclic, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.00042813323987193956, max_iter=2000, selection=cyclic, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.00042813323987193956, max_iter=2000, selection=cyclic, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=5.455594781168514, max_iter=3000, selection=random, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=5.455594781168514, max_iter=3000, selection=random, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=5.455594781168514, max_iter=3000, selection=random, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=5.455594781168514, max_iter=3000, selection=random, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=5.455594781168514, max_iter=3000, selection=random, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=11.288378916846883, max_iter=3000, selection=cyclic, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=11.288378916846883, max_iter=3000, selection=cyclic, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=11.288378916846883, max_iter=3000, selection=cyclic, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.00042813323987193956, max_iter=2000, selection=cyclic, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.0008858667904100823, max_iter=1000, selection=cyclic, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=11.288378916846883, max_iter=3000, selection=cyclic, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=11.288378916846883, max_iter=3000, selection=cyclic, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0008858667904100823, max_iter=1000, selection=cyclic, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0008858667904100823, max_iter=1000, selection=cyclic, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0008858667904100823, max_iter=1000, selection=cyclic, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0008858667904100823, max_iter=1000, selection=cyclic, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=5.455594781168514, max_iter=1000, selection=cyclic, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=5.455594781168514, max_iter=1000, selection=cyclic, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=5.455594781168514, max_iter=1000, selection=cyclic, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=5.455594781168514, max_iter=1000, selection=cyclic, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=5.455594781168514, max_iter=1000, selection=cyclic, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0001, max_iter=3000, selection=random, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=1.2742749857031321, max_iter=3000, selection=cyclic, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=1.2742749857031321, max_iter=3000, selection=cyclic, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=1.2742749857031321, max_iter=3000, selection=cyclic, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=1.2742749857031321, max_iter=3000, selection=cyclic, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=1.2742749857031321, max_iter=3000, selection=cyclic, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.007847599703514606, max_iter=3000, selection=random, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.007847599703514606, max_iter=3000, selection=random, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.007847599703514606, max_iter=3000, selection=random, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.007847599703514606, max_iter=3000, selection=random, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.007847599703514606, max_iter=3000, selection=random, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.0018329807108324356, max_iter=2000, selection=random, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.0018329807108324356, max_iter=2000, selection=random, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.0018329807108324356, max_iter=2000, selection=random, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.0018329807108324356, max_iter=2000, selection=random, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.0018329807108324356, max_iter=2000, selection=random, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=100.0, max_iter=3000, selection=cyclic, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=100.0, max_iter=3000, selection=cyclic, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=100.0, max_iter=3000, selection=cyclic, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=100.0, max_iter=3000, selection=cyclic, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=100.0, max_iter=3000, selection=cyclic, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.29763514416313164, max_iter=3000, selection=cyclic, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.29763514416313164, max_iter=3000, selection=cyclic, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.29763514416313164, max_iter=3000, selection=cyclic, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.29763514416313164, max_iter=3000, selection=cyclic, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.29763514416313164, max_iter=3000, selection=cyclic, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=48.32930238571752, max_iter=3000, selection=random, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=48.32930238571752, max_iter=3000, selection=random, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=48.32930238571752, max_iter=3000, selection=random, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=48.32930238571752, max_iter=3000, selection=random, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=48.32930238571752, max_iter=3000, selection=random, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.007847599703514606, max_iter=2000, selection=random, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.007847599703514606, max_iter=2000, selection=random, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.007847599703514606, max_iter=2000, selection=random, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.007847599703514606, max_iter=2000, selection=random, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.007847599703514606, max_iter=2000, selection=random, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.01623776739188721, max_iter=1000, selection=cyclic, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.01623776739188721, max_iter=1000, selection=cyclic, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.00042813323987193956, max_iter=2000, selection=cyclic, tol=0.0001; total time=   0.4s\n",
      "[CV] END alpha=0.01623776739188721, max_iter=1000, selection=cyclic, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.01623776739188721, max_iter=1000, selection=cyclic, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.01623776739188721, max_iter=1000, selection=cyclic, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.29763514416313164, max_iter=1000, selection=random, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.29763514416313164, max_iter=1000, selection=random, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0008858667904100823, max_iter=1000, selection=random, tol=0.0001; total time=   0.3s\n",
      "[CV] END alpha=0.29763514416313164, max_iter=1000, selection=random, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.29763514416313164, max_iter=1000, selection=random, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/fiber-orientation/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.824e+04, tolerance: 9.795e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/fiber-orientation/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.914e+04, tolerance: 9.890e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/fiber-orientation/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.205e+04, tolerance: 9.894e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.29763514416313164, max_iter=1000, selection=random, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=11.288378916846883, max_iter=3000, selection=cyclic, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=11.288378916846883, max_iter=3000, selection=cyclic, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=11.288378916846883, max_iter=3000, selection=cyclic, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.0008858667904100823, max_iter=1000, selection=random, tol=0.0001; total time=   0.3s\n",
      "[CV] END alpha=11.288378916846883, max_iter=3000, selection=cyclic, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.0008858667904100823, max_iter=1000, selection=random, tol=0.0001; total time=   0.3s\n",
      "[CV] END alpha=11.288378916846883, max_iter=3000, selection=cyclic, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.01623776739188721, max_iter=3000, selection=cyclic, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.01623776739188721, max_iter=3000, selection=cyclic, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.01623776739188721, max_iter=3000, selection=cyclic, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.01623776739188721, max_iter=3000, selection=cyclic, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.01623776739188721, max_iter=3000, selection=cyclic, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=100.0, max_iter=3000, selection=cyclic, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=100.0, max_iter=3000, selection=cyclic, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=100.0, max_iter=3000, selection=cyclic, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=100.0, max_iter=3000, selection=cyclic, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=100.0, max_iter=3000, selection=cyclic, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0008858667904100823, max_iter=1000, selection=random, tol=0.0001; total time=   0.1s\n",
      "[CV] END alpha=0.0008858667904100823, max_iter=1000, selection=random, tol=0.0001; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/fiber-orientation/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.665e+04, tolerance: 9.795e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.00042813323987193956, max_iter=2000, selection=cyclic, tol=0.0001; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/fiber-orientation/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.574e+05, tolerance: 9.890e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, max_iter=3000, selection=random, tol=0.0001; total time=   0.8s\n",
      "[CV] END alpha=0.0001, max_iter=3000, selection=random, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, max_iter=3000, selection=random, tol=0.0001; total time=   0.4s\n",
      "[CV] END alpha=0.0001, max_iter=3000, selection=random, tol=0.0001; total time=   0.0s\n",
      "\n",
      "Lasso Results:\n",
      "Best parameters: {'tol': 0.0001, 'selection': 'cyclic', 'max_iter': 1000, 'alpha': np.float64(0.01623776739188721)}\n",
      "Best MAE: 20.48째\n",
      "Lasso training time: 1.40 seconds\n"
     ]
    }
   ],
   "source": [
    "# Lasso evaluation\n",
    "start_time = time.time()\n",
    "lasso_params = {\n",
    "    'alpha': np.logspace(-4, 2, 20),\n",
    "    'max_iter': [1000, 2000, 3000],\n",
    "    'tol': [1e-4, 1e-3, 1e-2],\n",
    "    'selection': ['cyclic', 'random']\n",
    "}\n",
    "lasso_results = evaluate_model('Lasso', Lasso(), lasso_params)\n",
    "lasso_results['time'] = time.time() - start_time\n",
    "print(f\"Lasso training time: {lasso_results['time']:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] END .......................................alpha=0.0001; total time=   0.0s\n",
      "[CV] END .......................alpha=0.00020691380811147902; total time=   0.0s\n",
      "[CV] END .......................alpha=0.00020691380811147902; total time=   0.0s\n",
      "[CV] END .......................alpha=0.00020691380811147902; total time=   0.0s\n",
      "[CV] END .......................alpha=0.00042813323987193956; total time=   0.0s\n",
      "[CV] END .......................................alpha=0.0001; total time=   0.0s\n",
      "[CV] END .......................alpha=0.00042813323987193956; total time=   0.0s\n",
      "[CV] END .......................................alpha=0.0001; total time=   0.0s\n",
      "[CV] END .......................alpha=0.00020691380811147902; total time=   0.0s\n",
      "[CV] END .......................................alpha=0.0001; total time=   0.0s\n",
      "[CV] END .......................alpha=0.00020691380811147902; total time=   0.0s\n",
      "[CV] END .......................alpha=0.00042813323987193956; total time=   0.0s\n",
      "[CV] END .......................alpha=0.00042813323987193956; total time=   0.0s\n",
      "[CV] END .......................................alpha=0.0001; total time=   0.0s\n",
      "[CV] END .......................alpha=0.00042813323987193956; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0008858667904100823; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0008858667904100823; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0008858667904100823; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0018329807108324356; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0018329807108324356; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0018329807108324356; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0008858667904100823; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0008858667904100823; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0018329807108324356; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.00379269019073225; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.00379269019073225; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.00379269019073225; total time=   0.0s\n",
      "[CV] END .........................alpha=0.007847599703514606; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.00379269019073225; total time=   0.0s\n",
      "[CV] END .........................alpha=0.007847599703514606; total time=   0.0s\n",
      "[CV] END .........................alpha=0.007847599703514606; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.01623776739188721; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.01623776739188721; total time=   0.0s\n",
      "[CV] END .........................alpha=0.007847599703514606; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.01623776739188721; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.01623776739188721; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.01623776739188721; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.03359818286283781; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.03359818286283781; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.06951927961775606; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.03359818286283781; total time=   0.0s\n",
      "[CV] END ........................alpha=0.0018329807108324356; total time=   0.1s\n",
      "[CV] END ..........................alpha=0.00379269019073225; total time=   0.1s\n",
      "[CV] END ..........................alpha=0.06951927961775606; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.06951927961775606; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.14384498882876628; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.29763514416313164; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.06951927961775606; total time=   0.0s\n",
      "[CV] END .........................alpha=0.007847599703514606; total time=   0.1s\n",
      "[CV] END ..........................alpha=0.14384498882876628; total time=   0.0s\n",
      "[CV] END ............................alpha=0.615848211066026; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.14384498882876628; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.29763514416313164; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.14384498882876628; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.03359818286283781; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.29763514416313164; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.03359818286283781; total time=   0.1s\n",
      "[CV] END ............................alpha=0.615848211066026; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.14384498882876628; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.29763514416313164; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.29763514416313164; total time=   0.0s\n",
      "[CV] END ............................alpha=0.615848211066026; total time=   0.0s\n",
      "[CV] END ............................alpha=0.615848211066026; total time=   0.0s\n",
      "[CV] END ...........................alpha=1.2742749857031321; total time=   0.0s\n",
      "[CV] END ...........................alpha=2.6366508987303554; total time=   0.0s\n",
      "[CV] END ............................alpha=5.455594781168514; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.06951927961775606; total time=   0.1s\n",
      "[CV] END ...........................alpha=11.288378916846883; total time=   0.0s\n",
      "[CV] END ...........................alpha=1.2742749857031321; total time=   0.0s\n",
      "[CV] END ...........................alpha=2.6366508987303554; total time=   0.0s\n",
      "[CV] END ...........................alpha=11.288378916846883; total time=   0.0s\n",
      "[CV] END ...........................alpha=1.2742749857031321; total time=   0.0s\n",
      "[CV] END ...........................alpha=11.288378916846883; total time=   0.0s\n",
      "[CV] END ...........................alpha=11.288378916846883; total time=   0.0s\n",
      "[CV] END ...........................alpha=2.6366508987303554; total time=   0.0s\n",
      "[CV] END ...........................alpha=1.2742749857031321; total time=   0.0s\n",
      "[CV] END ............................alpha=0.615848211066026; total time=   0.0s\n",
      "[CV] END ............................alpha=5.455594781168514; total time=   0.0s\n",
      "[CV] END ...........................alpha=23.357214690901213; total time=   0.0s\n",
      "[CV] END ...........................alpha=2.6366508987303554; total time=   0.0s\n",
      "[CV] END ...........................alpha=11.288378916846883; total time=   0.0s\n",
      "[CV] END ...........................alpha=1.2742749857031321; total time=   0.0s\n",
      "[CV] END ...........................alpha=2.6366508987303554; total time=   0.0s\n",
      "[CV] END ...........................alpha=23.357214690901213; total time=   0.0s\n",
      "[CV] END ............................alpha=5.455594781168514; total time=   0.0s\n",
      "[CV] END ............................alpha=5.455594781168514; total time=   0.0s\n",
      "[CV] END ...........................alpha=23.357214690901213; total time=   0.0s\n",
      "[CV] END ............................alpha=48.32930238571752; total time=   0.0s\n",
      "[CV] END ............................alpha=48.32930238571752; total time=   0.0s\n",
      "[CV] END ............................alpha=48.32930238571752; total time=   0.0s\n",
      "[CV] END ............................alpha=5.455594781168514; total time=   0.0s\n",
      "[CV] END ............................alpha=48.32930238571752; total time=   0.0s\n",
      "[CV] END ............................alpha=48.32930238571752; total time=   0.0s\n",
      "[CV] END ........................................alpha=100.0; total time=   0.0s\n",
      "[CV] END ........................................alpha=100.0; total time=   0.0s\n",
      "[CV] END ...........................alpha=23.357214690901213; total time=   0.0s\n",
      "[CV] END ........................................alpha=100.0; total time=   0.0s\n",
      "[CV] END ........................................alpha=100.0; total time=   0.0s\n",
      "[CV] END ...........................alpha=23.357214690901213; total time=   0.1s\n",
      "[CV] END ........................................alpha=100.0; total time=   0.0s\n",
      "\n",
      "Ridge Results:\n",
      "Best parameters: {'alpha': np.float64(100.0)}\n",
      "Best MAE: 20.45째\n",
      "Ridge training time: 0.54 seconds\n"
     ]
    }
   ],
   "source": [
    "# Ridge evaluation\n",
    "start_time = time.time()\n",
    "ridge_params = {'alpha': np.logspace(-4, 2, 20)}\n",
    "ridge_results = evaluate_model('Ridge', Ridge(), ridge_params)\n",
    "ridge_results['time'] = time.time() - start_time\n",
    "print(f\"Ridge training time: {ridge_results['time']:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>mae</th>\n",
       "      <th>std</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'subsample': 0.9, 'n_estimators': 300, 'max_d...</td>\n",
       "      <td>10.342046</td>\n",
       "      <td>0.310933</td>\n",
       "      <td>78.510727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVR</td>\n",
       "      <td>{'kernel': 'rbf', 'gamma': 'scale', 'epsilon':...</td>\n",
       "      <td>13.185709</td>\n",
       "      <td>0.615814</td>\n",
       "      <td>74.388793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'n_estimators': 300, 'min_samples_split': 2, ...</td>\n",
       "      <td>19.096205</td>\n",
       "      <td>0.261280</td>\n",
       "      <td>64.138163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>{'alpha': 100.0}</td>\n",
       "      <td>20.453880</td>\n",
       "      <td>0.356296</td>\n",
       "      <td>0.543492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>{'tol': 0.0001, 'selection': 'cyclic', 'max_it...</td>\n",
       "      <td>20.483579</td>\n",
       "      <td>0.360604</td>\n",
       "      <td>1.403451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model                                             params  \\\n",
       "2        XGBoost  {'subsample': 0.9, 'n_estimators': 300, 'max_d...   \n",
       "0            SVR  {'kernel': 'rbf', 'gamma': 'scale', 'epsilon':...   \n",
       "1  Random Forest  {'n_estimators': 300, 'min_samples_split': 2, ...   \n",
       "3          Ridge                                   {'alpha': 100.0}   \n",
       "4          Lasso  {'tol': 0.0001, 'selection': 'cyclic', 'max_it...   \n",
       "\n",
       "         mae       std       time  \n",
       "2  10.342046  0.310933  78.510727  \n",
       "0  13.185709  0.615814  74.388793  \n",
       "1  19.096205  0.261280  64.138163  \n",
       "3  20.453880  0.356296   0.543492  \n",
       "4  20.483579  0.360604   1.403451  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compile and compare results\n",
    "results = [svr_results, rf_results, xgb_results, ridge_results, lasso_results]\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('mae')\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(range(len(results_df)), \n",
    "             results_df['mae'], \n",
    "             yerr=results_df['std'],\n",
    "             fmt='o',\n",
    "             capsize=5)\n",
    "\n",
    "plt.xticks(range(len(results_df)), results_df['model'], rotation=45)\n",
    "plt.ylabel('Mean Absolute Error (degrees)')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save results\n",
    "print(\"\\nDetailed Results:\")\n",
    "display(results_df)\n",
    "results_df.to_csv('../models/svr_hog/regressor_comparison.csv', index=False)\n",
    "\n",
    "# Save best model config\n",
    "best_config = {\n",
    "    'model': results_df.iloc[0]['model'],\n",
    "    'parameters': results_df.iloc[0]['params'],\n",
    "    'mae': float(results_df.iloc[0]['mae']),\n",
    "    'std': float(results_df.iloc[0]['std'])\n",
    "}\n",
    "\n",
    "with open('../models/svr_hog/best_regressor.json', 'w') as f:\n",
    "    json.dump(best_config, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fiber-orientation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
